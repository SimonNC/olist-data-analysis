{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e7da083b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\simon\\.cache\\kagglehub\\datasets\\olistbr\\brazilian-ecommerce\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "#Package to download datasets from kaggle\n",
    "#%pip install kagglehub\n",
    "# %pip install fastparquet\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
    "PROJECT_ROOT = Path(\"..\")\n",
    "DATA_CLEANED_DIR = PROJECT_ROOT / \"data_cleaned\"\n",
    "DATA_CLEANED_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6248d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_profile(df):\n",
    "    \"\"\"\n",
    "    Displays a quick profile of a pandas DataFrame.\n",
    "    Purpose: provide a high-level overview of the dataset structure,\n",
    "    data quality, and basic statistics (quick EDA).\n",
    "    \"\"\"\n",
    "\n",
    "    # Shape of the DataFrame: (number of rows, number of columns)\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "\n",
    "    # List of column names\n",
    "    print(f\"\\nData columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Data types of each column (int, float, object, datetime, etc.)\n",
    "    print(f\"\\nData types: {df.dtypes}\")\n",
    "\n",
    "    # Descriptive statistics for numerical variables\n",
    "    # Includes: count, mean, std, min, quartiles, and max\n",
    "    print(f\"\\nData description: {df.describe()}\")\n",
    "\n",
    "    # Number of missing values per column\n",
    "    # Helps identify data quality issues\n",
    "    print(f\"\\nData missing values: {df.isnull().sum()}\")\n",
    "\n",
    "    # Number of duplicated rows in the DataFrame\n",
    "    # Important to detect potential bias in analysis\n",
    "    print(f\"\\nData duplicates: {df.duplicated().sum()}\")\n",
    "\n",
    "\n",
    "def report(df, name):\n",
    "    \"\"\"\n",
    "    Display a quick validation report for a DataFrame.\n",
    "\n",
    "    Purpose:\n",
    "    - Confirm that the dataset has been correctly processed\n",
    "    - Provide a lightweight sanity check after cleaning or transformation steps\n",
    "    \"\"\"\n",
    "\n",
    "    # Display dataset name for traceability in the pipeline\n",
    "    print(f\"✅ {name}.csv saved!\")\n",
    "\n",
    "    # Print the DataFrame shape (rows, columns) to validate size expectations\n",
    "    print(\"Shape:\", df.shape)\n",
    "\n",
    "    # Display the first rows to visually inspect the output\n",
    "    print(df.head())\n",
    "\n",
    "\n",
    "def export_clean(df, name, out_dir=DATA_CLEANED_DIR):\n",
    "    \"\"\"\n",
    "    Export a cleaned DataFrame to both CSV and Parquet formats.\n",
    "\n",
    "    Purpose:\n",
    "    - CSV: human-readable format for inspection and versioning\n",
    "    - Parquet: optimized columnar format for performance and type safety\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    assert out_dir.exists(), \"Output directory does not exist\"\n",
    "\n",
    "\n",
    "    # Build output file paths\n",
    "    csv_path = os.path.join(out_dir, f\"{name}.csv\")\n",
    "    parquet_path = os.path.join(out_dir, f\"{name}.parquet\")\n",
    "\n",
    "    # Export to CSV (universal, easy to inspect)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Export to Parquet using pyarrow\n",
    "    # This approach bypasses some pandas/pyarrow compatibility issues\n",
    "    # and ensures a robust Parquet write\n",
    "    table = pa.Table.from_pandas(df, preserve_index=False)\n",
    "    pq.write_table(table, parquet_path)\n",
    "\n",
    "    # Confirmation message\n",
    "    print(f\"✅ Saved: {csv_path} and {parquet_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bbd6f",
   "metadata": {},
   "source": [
    "### 1. Orders Table\n",
    "\n",
    "#### 1.1 Load raw data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c23f3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the orders dataset\n",
    "orders_raw = pd.read_csv(os.path.join(path, \"olist_orders_dataset.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e35a77f",
   "metadata": {},
   "source": [
    "#### 1.2 Profiling\n",
    "\n",
    "- Reviewed dataset structure, columns, and data types\n",
    "- Analyzed order status distribution\n",
    "- Identified key timestamps for order lifecycle analysis\n",
    "- Flagged early-stage statuses not relevant for delivery performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "82cd04a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (99441, 8)\n",
      "\n",
      "Data columns: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
      "\n",
      "Data types: order_id                         object\n",
      "customer_id                      object\n",
      "order_status                     object\n",
      "order_purchase_timestamp         object\n",
      "order_approved_at                object\n",
      "order_delivered_carrier_date     object\n",
      "order_delivered_customer_date    object\n",
      "order_estimated_delivery_date    object\n",
      "dtype: object\n",
      "\n",
      "Data description:                                 order_id                       customer_id  \\\n",
      "count                              99441                             99441   \n",
      "unique                             99441                             99441   \n",
      "top     66dea50a8b16d9b4dee7af250b4be1a5  edb027a75a1449115f6b43211ae02a24   \n",
      "freq                                   1                                 1   \n",
      "\n",
      "       order_status order_purchase_timestamp    order_approved_at  \\\n",
      "count         99441                    99441                99281   \n",
      "unique            8                    98875                90733   \n",
      "top       delivered      2018-08-02 12:05:26  2018-02-27 04:31:10   \n",
      "freq          96478                        3                    9   \n",
      "\n",
      "       order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "count                         97658                         96476   \n",
      "unique                        81018                         95664   \n",
      "top             2018-05-09 15:48:00           2018-05-08 19:36:48   \n",
      "freq                             47                             3   \n",
      "\n",
      "       order_estimated_delivery_date  \n",
      "count                          99441  \n",
      "unique                           459  \n",
      "top              2017-12-20 00:00:00  \n",
      "freq                             522  \n",
      "\n",
      "Data missing values: order_id                            0\n",
      "customer_id                         0\n",
      "order_status                        0\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                 160\n",
      "order_delivered_carrier_date     1783\n",
      "order_delivered_customer_date    2965\n",
      "order_estimated_delivery_date       0\n",
      "dtype: int64\n",
      "\n",
      "Data duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Quick data profile\n",
    "data_profile(orders_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0945f",
   "metadata": {},
   "source": [
    "#### 1.3 Data Cleaning\n",
    "\n",
    "- Selected columns required for order lifecycle and delivery analysis\n",
    "- Converted timestamp fields to datetime format\n",
    "- Standardized order_status values to lowercase\n",
    "- Excluded early-stage orders (`created`, `approved`)\n",
    "- Applied data quality checks (primary key uniqueness, non-null status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e3ab73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Column selection\n",
    "# Keep only the columns required for order lifecycle and delivery analysis\n",
    "# Use .copy() to avoid pandas chained assignment issues (SettingWithCopyWarning)\n",
    "# ------------------------------------------------------------------------------\n",
    "orders_clean = orders_raw[[\n",
    "    \"order_id\",\n",
    "    \"customer_id\",\n",
    "    \"order_status\",\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "]].copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Date parsing\n",
    "# Convert timestamp columns to pandas datetime for time-based analysis\n",
    "# Invalid or malformed values are coerced to NaT (missing)\n",
    "# ------------------------------------------------------------------------------\n",
    "date_cols = [\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "]\n",
    "orders_clean[date_cols] = orders_clean[date_cols].apply(pd.to_datetime, errors=\"coerce\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Categorical normalization\n",
    "# Standardize order_status values to lowercase to prevent case inconsistencies\n",
    "# ------------------------------------------------------------------------------\n",
    "orders_clean[\"order_status\"] = orders_clean[\"order_status\"].str.lower()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Business rule filtering\n",
    "# Exclude early-stage orders that are not relevant for delivery/performance analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "EXCLUDED_ORDER_STATUSES = {\"created\", \"approved\"}\n",
    "orders_clean = orders_clean.loc[\n",
    "    ~orders_clean[\"order_status\"].isin(EXCLUDED_ORDER_STATUSES)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d7141",
   "metadata": {},
   "source": [
    "#### 1.4 Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3787755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Stop the pipeline early if key assumptions are violated\n",
    "# ------------------------------------------------------------------------------\n",
    "assert orders_clean[\"order_id\"].notna().all(), \"order_id contains missing values\"\n",
    "assert orders_clean[\"order_id\"].is_unique, \"order_id is not unique\"\n",
    "assert orders_clean[\"order_status\"].notna().all(), \"order_status contains missing values\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4502388f",
   "metadata": {},
   "source": [
    "#### 1.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/orders_clean.csv`\n",
    "- `data_cleaned/orders_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4fa3ccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ..\\data_cleaned\\orders_clean.csv and ..\\data_cleaned\\orders_clean.parquet\n",
      "✅ orders_clean.csv saved!\n",
      "Shape: (99434, 6)\n",
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp order_delivered_customer_date  \\\n",
      "0    delivered      2017-10-02 10:56:33           2017-10-10 21:25:13   \n",
      "1    delivered      2018-07-24 20:41:37           2018-08-07 15:27:45   \n",
      "2    delivered      2018-08-08 08:38:49           2018-08-17 18:06:29   \n",
      "3    delivered      2017-11-18 19:28:06           2017-12-02 00:28:42   \n",
      "4    delivered      2018-02-13 21:18:39           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  \n",
      "0                    2017-10-18  \n",
      "1                    2018-08-13  \n",
      "2                    2018-09-04  \n",
      "3                    2017-12-15  \n",
      "4                    2018-02-26  \n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned dataset\n",
    "# Save the cleaned table for downstream analysis and dashboarding\n",
    "# ------------------------------------------------------------------------------\n",
    "export_clean(orders_clean, \"orders_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity check report\n",
    "# Quick visual validation: shape + head\n",
    "# ------------------------------------------------------------------------------\n",
    "report(orders_clean, \"orders_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922094d",
   "metadata": {},
   "source": [
    "### 2. Customers Table\n",
    "\n",
    "#### 2.1 Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "232ee23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the customers dataset\n",
    "customers_raw = pd.read_csv(os.path.join(path, \"olist_customers_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2f9cf",
   "metadata": {},
   "source": [
    "#### 2.2 Profiling\n",
    "\n",
    "- Inspected dataset structure and data types\n",
    "- Checked for missing values\n",
    "- Identified customer_id as the primary key\n",
    "- Identified customer_state for regional analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "51a69a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (99441, 5)\n",
      "\n",
      "Data columns: ['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']\n",
      "\n",
      "Data types: customer_id                 object\n",
      "customer_unique_id          object\n",
      "customer_zip_code_prefix     int64\n",
      "customer_city               object\n",
      "customer_state              object\n",
      "dtype: object\n",
      "\n",
      "Data description:        customer_zip_code_prefix\n",
      "count              99441.000000\n",
      "mean               35137.474583\n",
      "std                29797.938996\n",
      "min                 1003.000000\n",
      "25%                11347.000000\n",
      "50%                24416.000000\n",
      "75%                58900.000000\n",
      "max                99990.000000\n",
      "\n",
      "Data missing values: customer_id                 0\n",
      "customer_unique_id          0\n",
      "customer_zip_code_prefix    0\n",
      "customer_city               0\n",
      "customer_state              0\n",
      "dtype: int64\n",
      "\n",
      "Data duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Quick data profile\n",
    "data_profile(customers_raw) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c342bf69",
   "metadata": {},
   "source": [
    "#### 2.3 Data cleaning\n",
    "\n",
    "- Retained only customer_id and customer_state\n",
    "- Applied data quality checks (primary key uniqueness, non-null state codes)\n",
    "- Validated customer_state format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2b9cbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Column selection\n",
    "# Keep only the columns required for customer-level and regional analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "customers_clean = customers_raw[[\n",
    "    \"customer_id\",\n",
    "    \"customer_state\"\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af833b77",
   "metadata": {},
   "source": [
    "#### 2.4 Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e0c86c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Validate key assumptions before exporting the dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Primary key checks\n",
    "assert customers_clean[\"customer_id\"].notna().all(), \\\n",
    "    \"customer_id contains missing values\"\n",
    "assert customers_clean[\"customer_id\"].is_unique, \\\n",
    "    \"customer_id is not unique\"\n",
    "\n",
    "# Categorical integrity checks\n",
    "assert customers_clean[\"customer_state\"].notna().all(), \\\n",
    "    \"customer_state contains missing values\"\n",
    "\n",
    "# Optional: validate state code format (Brazilian states = 2-letter codes)\n",
    "assert customers_clean[\"customer_state\"].str.len().eq(2).all(), \\\n",
    "    \"Invalid customer_state code detected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89766b15",
   "metadata": {},
   "source": [
    "#### 2.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/customers_clean.csv`\n",
    "- `data_cleaned/customers_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a9ce1088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ..\\data_cleaned\\customers_clean.csv and ..\\data_cleaned\\customers_clean.parquet\n",
      "✅ customers_clean.csv saved!\n",
      "Shape: (99441, 2)\n",
      "                        customer_id customer_state\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7             SP\n",
      "1  18955e83d337fd6b2def6b18a428ac77             SP\n",
      "2  4e7b3e00288586ebd08712fdd0374a03             SP\n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3             SP\n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad             SP\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned dataset\n",
    "# Ensure the output directory exists and save the cleaned table\n",
    "# ------------------------------------------------------------------------------\n",
    "# os.makedirs(\"data_cleaned\", exist_ok=True)\n",
    "export_clean(customers_clean, \"customers_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity checks\n",
    "# Display basic information to validate the cleaning process\n",
    "# ------------------------------------------------------------------------------\n",
    "report(customers_clean, \"customers_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd875e6",
   "metadata": {},
   "source": [
    "### 3. Order Items Table\n",
    "\n",
    "#### 3.1 Load raw data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5d4080b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items_raw = pd.read_csv(os.path.join(path, \"olist_order_items_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb22011",
   "metadata": {},
   "source": [
    "#### 3.2 Profiling\n",
    "\n",
    "- Reviewed dataset structure and data types\n",
    "- Analyzed price and freight_value distributions\n",
    "- Identified key columns for revenue and shipping cost analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e43b13cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (112650, 7)\n",
      "\n",
      "Data columns: ['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value']\n",
      "\n",
      "Data types: order_id                object\n",
      "order_item_id            int64\n",
      "product_id              object\n",
      "seller_id               object\n",
      "shipping_limit_date     object\n",
      "price                  float64\n",
      "freight_value          float64\n",
      "dtype: object\n",
      "\n",
      "Data description:        order_item_id          price  freight_value\n",
      "count  112650.000000  112650.000000  112650.000000\n",
      "mean        1.197834     120.653739      19.990320\n",
      "std         0.705124     183.633928      15.806405\n",
      "min         1.000000       0.850000       0.000000\n",
      "25%         1.000000      39.900000      13.080000\n",
      "50%         1.000000      74.990000      16.260000\n",
      "75%         1.000000     134.900000      21.150000\n",
      "max        21.000000    6735.000000     409.680000\n",
      "\n",
      "Data missing values: order_id               0\n",
      "order_item_id          0\n",
      "product_id             0\n",
      "seller_id              0\n",
      "shipping_limit_date    0\n",
      "price                  0\n",
      "freight_value          0\n",
      "dtype: int64\n",
      "\n",
      "Data duplicates: 0\n",
      "\n",
      "Price summary:\n",
      "count    112650.000000\n",
      "mean        120.653739\n",
      "std         183.633928\n",
      "min           0.850000\n",
      "25%          39.900000\n",
      "50%          74.990000\n",
      "75%         134.900000\n",
      "max        6735.000000\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Freight summary:\n",
      "count    112650.000000\n",
      "mean         19.990320\n",
      "std          15.806405\n",
      "min           0.000000\n",
      "25%          13.080000\n",
      "50%          16.260000\n",
      "75%          21.150000\n",
      "max         409.680000\n",
      "Name: freight_value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Order items – Data profiling\n",
    "# Explore structure, data quality, and key numerical metrics\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Generate a high-level overview of the raw order_items dataset\n",
    "# (shape, columns, data types, missing values, duplicates)\n",
    "data_profile(order_items_raw)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Numerical exploration: price\n",
    "# Analyze distribution and summary statistics to understand revenue patterns\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\nPrice summary:\")\n",
    "print(order_items_raw[\"price\"].describe())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Numerical exploration: freight_value\n",
    "# Analyze shipping cost distribution and identify potential outliers\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\nFreight summary:\")\n",
    "print(order_items_raw[\"freight_value\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b7f4c",
   "metadata": {},
   "source": [
    "#### 3.3 Data Cleaning\n",
    "\n",
    "- Selected relevant columns for analysis\n",
    "- Converted price and freight_value to numeric types\n",
    "- Applied data quality checks (non-null, non-negative values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "08337c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Column selection\n",
    "# Keep only the columns required for revenue and shipping cost analysis\n",
    "# Use .copy() to avoid chained assignment issues\n",
    "# ------------------------------------------------------------------------------\n",
    "order_items_clean = order_items_raw[[\n",
    "    \"order_id\",\n",
    "    \"product_id\",\n",
    "    \"price\",\n",
    "    \"freight_value\"\n",
    "]].copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Data type conversion\n",
    "# Ensure price and freight_value are numeric for reliable aggregations\n",
    "# Invalid values are coerced to NaN\n",
    "# ------------------------------------------------------------------------------\n",
    "order_items_clean[\"price\"] = pd.to_numeric(\n",
    "    order_items_clean[\"price\"], errors=\"coerce\"\n",
    ")\n",
    "order_items_clean[\"freight_value\"] = pd.to_numeric(\n",
    "    order_items_clean[\"freight_value\"], errors=\"coerce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00706fa7",
   "metadata": {},
   "source": [
    "#### 3.4 Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "eb38cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Validate business assumptions before exporting the dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "assert order_items_clean[\"price\"].notna().all(), \"Missing values detected in price\"\n",
    "assert order_items_clean[\"freight_value\"].notna().all(), \"Missing values detected in freight_value\"\n",
    "\n",
    "assert (order_items_clean[\"price\"] >= 0).all(), \"Negative price values detected\"\n",
    "assert (order_items_clean[\"freight_value\"] >= 0).all(), \"Negative freight values detected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f00ace",
   "metadata": {},
   "source": [
    "#### 3.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/order_items_clean.csv`\n",
    "- `data_cleaned/order_items_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6c3b0e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ..\\data_cleaned\\order_items_clean.csv and ..\\data_cleaned\\order_items_clean.parquet\n",
      "✅ order_items_clean.csv saved!\n",
      "Shape: (112650, 4)\n",
      "                           order_id                        product_id   price  \\\n",
      "0  00010242fe8c5a6d1ba2dd792cb16214  4244733e06e7ecb4970a6e2683c13e61   58.90   \n",
      "1  00018f77f2f0320c557190d7a144bdd3  e5f2d52b802189ee658865ca93d83a8f  239.90   \n",
      "2  000229ec398224ef6ca0657da4fc703e  c777355d18b72b67abbeef9df44fd0fd  199.00   \n",
      "3  00024acbcdf0a6daa1e931b038114c75  7634da152a4610f1595efa32f14722fc   12.99   \n",
      "4  00042b26cf59d7ce69dfabb4e55b4fd9  ac6c3623068f30de03045865e4e10089  199.90   \n",
      "\n",
      "   freight_value  \n",
      "0          13.29  \n",
      "1          19.93  \n",
      "2          17.87  \n",
      "3          12.79  \n",
      "4          18.14  \n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned dataset\n",
    "# Save the cleaned order items table for downstream analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "export_clean(order_items_clean, \"order_items_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity check report\n",
    "# Quick validation of shape and sample rows\n",
    "# ------------------------------------------------------------------------------\n",
    "report(order_items_clean, \"order_items_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba47a5",
   "metadata": {},
   "source": [
    "### 4. Products Table\n",
    "\n",
    "#### 4.1 Load raw data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "34484c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Load products dataset\n",
    "# Read the raw products table from the source CSV file\n",
    "# ------------------------------------------------------------------------------\n",
    "products_raw = pd.read_csv(os.path.join(path, \"olist_products_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab51bc",
   "metadata": {},
   "source": [
    "#### 4.2 Profiling\n",
    "\n",
    "- Inspected dataset structure and category distribution\n",
    "- Identified product_category_name as the main analytical dimension\n",
    "- Flagged descriptive and physical attributes as out of scope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9eb759f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (32951, 9)\n",
      "\n",
      "Data columns: ['product_id', 'product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
      "\n",
      "Data types: product_id                     object\n",
      "product_category_name          object\n",
      "product_name_lenght           float64\n",
      "product_description_lenght    float64\n",
      "product_photos_qty            float64\n",
      "product_weight_g              float64\n",
      "product_length_cm             float64\n",
      "product_height_cm             float64\n",
      "product_width_cm              float64\n",
      "dtype: object\n",
      "\n",
      "Data description:        product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
      "count         32341.000000                32341.000000        32341.000000   \n",
      "mean             48.476949                  771.495285            2.188986   \n",
      "std              10.245741                  635.115225            1.736766   \n",
      "min               5.000000                    4.000000            1.000000   \n",
      "25%              42.000000                  339.000000            1.000000   \n",
      "50%              51.000000                  595.000000            1.000000   \n",
      "75%              57.000000                  972.000000            3.000000   \n",
      "max              76.000000                 3992.000000           20.000000   \n",
      "\n",
      "       product_weight_g  product_length_cm  product_height_cm  \\\n",
      "count      32949.000000       32949.000000       32949.000000   \n",
      "mean        2276.472488          30.815078          16.937661   \n",
      "std         4282.038731          16.914458          13.637554   \n",
      "min            0.000000           7.000000           2.000000   \n",
      "25%          300.000000          18.000000           8.000000   \n",
      "50%          700.000000          25.000000          13.000000   \n",
      "75%         1900.000000          38.000000          21.000000   \n",
      "max        40425.000000         105.000000         105.000000   \n",
      "\n",
      "       product_width_cm  \n",
      "count      32949.000000  \n",
      "mean          23.196728  \n",
      "std           12.079047  \n",
      "min            6.000000  \n",
      "25%           15.000000  \n",
      "50%           20.000000  \n",
      "75%           30.000000  \n",
      "max          118.000000  \n",
      "\n",
      "Data missing values: product_id                      0\n",
      "product_category_name         610\n",
      "product_name_lenght           610\n",
      "product_description_lenght    610\n",
      "product_photos_qty            610\n",
      "product_weight_g                2\n",
      "product_length_cm               2\n",
      "product_height_cm               2\n",
      "product_width_cm                2\n",
      "dtype: int64\n",
      "\n",
      "Data duplicates: 0\n",
      "\n",
      "Unique categories: 73\n",
      "['perfumaria' 'artes' 'esporte_lazer' 'bebes' 'utilidades_domesticas'\n",
      " 'instrumentos_musicais' 'cool_stuff' 'moveis_decoracao'\n",
      " 'eletrodomesticos' 'brinquedos' 'cama_mesa_banho'\n",
      " 'construcao_ferramentas_seguranca' 'informatica_acessorios'\n",
      " 'beleza_saude' 'malas_acessorios']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Initial data profiling\n",
    "# Generate a high-level overview of the dataset structure and data quality\n",
    "# ------------------------------------------------------------------------------\n",
    "data_profile(products_raw)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Categorical exploration\n",
    "# Analyze product categories to understand cardinality and sample values\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\nUnique categories:\", products_raw[\"product_category_name\"].nunique())\n",
    "\n",
    "# Display a sample of category values for quick inspection\n",
    "print(products_raw[\"product_category_name\"].unique()[:15])  # first 15 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feb4ce1",
   "metadata": {},
   "source": [
    "#### 4.3 Data Cleaning\n",
    "\n",
    "- Retained product_id and product_category_name\n",
    "- Replaced missing categories with \"unknown\"\n",
    "- Standardized category values\n",
    "- Applied data quality checks (primary key uniqueness, non-empty categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1c0502de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Column selection\n",
    "# Keep only the fields required for product-level and category analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "products_clean = products_raw[[\n",
    "    \"product_id\",\n",
    "    \"product_category_name\"\n",
    "]].copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Missing value handling\n",
    "# Replace missing product categories with \"unknown\" to preserve completeness\n",
    "# and avoid issues during grouping or joins\n",
    "# ------------------------------------------------------------------------------\n",
    "products_clean[\"product_category_name\"] = (\n",
    "    products_clean[\"product_category_name\"]\n",
    "    .fillna(\"unknown\")\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d31ee",
   "metadata": {},
   "source": [
    "#### 4.4 Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "724e04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Validate key assumptions before exporting the dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Primary key checks\n",
    "assert products_clean[\"product_id\"].notna().all(), \"product_id contains missing values\"\n",
    "assert products_clean[\"product_id\"].is_unique, \"product_id is not unique\"\n",
    "\n",
    "# Category checks\n",
    "assert products_clean[\"product_category_name\"].notna().all(), \\\n",
    "    \"product_category_name contains missing values after fillna\"\n",
    "\n",
    "# No empty strings after cleaning\n",
    "assert (products_clean[\"product_category_name\"].str.len() > 0).all(), \\\n",
    "    \"Empty product_category_name values detected\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53bbf50",
   "metadata": {},
   "source": [
    "#### 4.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/products_clean.csv`\n",
    "- `data_cleaned/products_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "137d2393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ..\\data_cleaned\\products_clean.csv and ..\\data_cleaned\\products_clean.parquet\n",
      "✅ products_clean.csv saved!\n",
      "Shape: (32951, 2)\n",
      "                         product_id  product_category_name\n",
      "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria\n",
      "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes\n",
      "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer\n",
      "3  cef67bcfe19066a932b7673e239eb23d                  bebes\n",
      "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned dataset\n",
    "# Save the cleaned products table for downstream analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "export_clean(products_clean, \"products_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity checks\n",
    "# Quick validation of shape and sample rows\n",
    "# ------------------------------------------------------------------------------\n",
    "report(products_clean, \"products_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec47fc",
   "metadata": {},
   "source": [
    "### 5. Product Category Translation Table\n",
    "\n",
    "#### 5.1 Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3905d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Load category translation table\n",
    "# Read the product category translation lookup table\n",
    "# (Portuguese → English)\n",
    "# ------------------------------------------------------------------------------\n",
    "translation_raw = pd.read_csv(\n",
    "    os.path.join(path, \"product_category_name_translation.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff1bb4c",
   "metadata": {},
   "source": [
    "#### 5.2 Profiling\n",
    "\n",
    "- Reviewed lookup table structure\n",
    "- Confirmed absence of missing values\n",
    "- Identified the table as a Portuguese-to-English category mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6149644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (71, 2)\n",
      "\n",
      "Data columns: ['product_category_name', 'product_category_name_english']\n",
      "\n",
      "Data types: product_category_name            object\n",
      "product_category_name_english    object\n",
      "dtype: object\n",
      "\n",
      "Data description:        product_category_name product_category_name_english\n",
      "count                     71                            71\n",
      "unique                    71                            71\n",
      "top             beleza_saude                 health_beauty\n",
      "freq                       1                             1\n",
      "\n",
      "Data missing values: product_category_name            0\n",
      "product_category_name_english    0\n",
      "dtype: int64\n",
      "\n",
      "Data duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Initial data profiling\n",
    "# Generate a high-level overview to validate structure and data quality\n",
    "# ------------------------------------------------------------------------------\n",
    "data_profile(translation_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666163a",
   "metadata": {},
   "source": [
    "#### 5.3 Data Cleaning\n",
    "\n",
    "- Renamed columns for clarity\n",
    "- Standardized text fields\n",
    "- Applied data quality checks (unique mapping, non-null values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9bd381d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Column renaming\n",
    "# Rename columns to improve clarity and semantic meaning\n",
    "# ------------------------------------------------------------------------------\n",
    "translation_clean = translation_raw.rename(columns={\n",
    "    \"product_category_name\": \"category_portuguese\",\n",
    "    \"product_category_name_english\": \"category_english\"\n",
    "}).copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# String normalization\n",
    "# Standardize text fields to reduce join mismatches (spaces/case)\n",
    "# ------------------------------------------------------------------------------\n",
    "translation_clean[\"category_portuguese\"] = (\n",
    "    translation_clean[\"category_portuguese\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "translation_clean[\"category_english\"] = (\n",
    "    translation_clean[\"category_english\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8362e3a6",
   "metadata": {},
   "source": [
    "#### 5.4  Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a7f387e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Validate lookup integrity before exporting the dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# No missing values (expected for a translation lookup table)\n",
    "assert translation_clean[\"category_portuguese\"].notna().all(), \\\n",
    "    \"category_portuguese contains missing values\"\n",
    "assert translation_clean[\"category_english\"].notna().all(), \\\n",
    "    \"category_english contains missing values\"\n",
    "\n",
    "# No empty strings after cleaning\n",
    "assert (translation_clean[\"category_portuguese\"].str.len() > 0).all(), \\\n",
    "    \"Empty category_portuguese values detected\"\n",
    "assert (translation_clean[\"category_english\"].str.len() > 0).all(), \\\n",
    "    \"Empty category_english values detected\"\n",
    "\n",
    "# Key uniqueness: one Portuguese category should map to one English category\n",
    "assert translation_clean[\"category_portuguese\"].is_unique, \\\n",
    "    \"Duplicate category_portuguese detected (mapping should be 1-to-1)\"\n",
    "\n",
    "# Optional: sanity check for duplicates on the full pair (PT, EN)\n",
    "assert translation_clean.duplicated(\n",
    "    subset=[\"category_portuguese\", \"category_english\"]\n",
    ").sum() == 0, \"Duplicate translation pairs detected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d444af",
   "metadata": {},
   "source": [
    "#### 5.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/category_translation_clean.csv`\n",
    "- `data_cleaned/category_translation_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a97e8552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ..\\data_cleaned\\translation_clean.csv and ..\\data_cleaned\\translation_clean.parquet\n",
      "✅ translation_clean.csv saved!\n",
      "Shape: (71, 2)\n",
      "      category_portuguese       category_english\n",
      "0            beleza_saude          health_beauty\n",
      "1  informatica_acessorios  computers_accessories\n",
      "2              automotivo                   auto\n",
      "3         cama_mesa_banho         bed_bath_table\n",
      "4        moveis_decoracao        furniture_decor\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned translation table\n",
    "# Ensure the output directory exists and save the cleaned lookup table\n",
    "# ------------------------------------------------------------------------------\n",
    "export_clean(translation_clean, \"translation_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity checks\n",
    "# Quick validation of shape and sample rows\n",
    "# ------------------------------------------------------------------------------\n",
    "report(translation_clean, \"translation_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86cc5c9",
   "metadata": {},
   "source": [
    "### 6. Reviews Table\n",
    "\n",
    "#### 6.1 Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ea270074",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_raw = pd.read_csv(\n",
    "    os.path.join(path, \"olist_order_reviews_dataset.csv\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf1abe",
   "metadata": {},
   "source": [
    "#### 6.2 Profiling\n",
    "\n",
    "- Reviewed dataset structure, columns, and data types\n",
    "- Identified `order_id` as the join key with the orders table\n",
    "- Analyzed the distribution of `review_score` to assess customer satisfaction patterns\n",
    "- Verified that review scores follow a discrete rating scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "93ad16bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (99224, 7)\n",
      "\n",
      "Data columns: ['review_id', 'order_id', 'review_score', 'review_comment_title', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp']\n",
      "\n",
      "Data types: review_id                  object\n",
      "order_id                   object\n",
      "review_score                int64\n",
      "review_comment_title       object\n",
      "review_comment_message     object\n",
      "review_creation_date       object\n",
      "review_answer_timestamp    object\n",
      "dtype: object\n",
      "\n",
      "Data description:        review_score\n",
      "count  99224.000000\n",
      "mean       4.086421\n",
      "std        1.347579\n",
      "min        1.000000\n",
      "25%        4.000000\n",
      "50%        5.000000\n",
      "75%        5.000000\n",
      "max        5.000000\n",
      "\n",
      "Data missing values: review_id                      0\n",
      "order_id                       0\n",
      "review_score                   0\n",
      "review_comment_title       87656\n",
      "review_comment_message     58247\n",
      "review_creation_date           0\n",
      "review_answer_timestamp        0\n",
      "dtype: int64\n",
      "\n",
      "Data duplicates: 0\n",
      "\n",
      "Review score distribution:\n",
      "review_score\n",
      "5    57328\n",
      "4    19142\n",
      "1    11424\n",
      "3     8179\n",
      "2     3151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_profile(reviews_raw)\n",
    "\n",
    "print(\"\\nReview score distribution:\")\n",
    "print(reviews_raw['review_score'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d22e3",
   "metadata": {},
   "source": [
    "#### 6.3 Data Cleaning\n",
    "\n",
    "- Selected only the columns required for satisfaction analysis:\n",
    "  - `order_id`\n",
    "  - `review_score`\n",
    "- Ensured `review_score` values are numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6251f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_clean = reviews_raw[[\"order_id\", \"review_score\"]].copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3488144f",
   "metadata": {},
   "source": [
    "#### 6.4 Data quality checks\n",
    "\n",
    "- Applied data quality checks:\n",
    "  - non-null `order_id`\n",
    "  - non-null `review_score`\n",
    "  - review scores constrained to the expected range (1–5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a1aaaa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Validate assumptions for reviews data\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# order_id must be present for joins with orders\n",
    "assert reviews_clean[\"order_id\"].notna().all(), \\\n",
    "    \"order_id contains missing values in reviews table\"\n",
    "\n",
    "# review_score must be present\n",
    "assert reviews_clean[\"review_score\"].notna().all(), \\\n",
    "    \"review_score contains missing values\"\n",
    "\n",
    "# review_score must be numeric\n",
    "assert pd.api.types.is_numeric_dtype(reviews_clean[\"review_score\"]), \\\n",
    "    \"review_score is not numeric\"\n",
    "\n",
    "# review_score must be within expected rating scale (1 to 5)\n",
    "assert reviews_clean[\"review_score\"].between(1, 5).all(), \\\n",
    "    \"review_score outside expected range (1–5)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde901cd",
   "metadata": {},
   "source": [
    "#### 6.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/reviews_clean.csv`\n",
    "- `data_cleaned/reviews_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "43351fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ..\\data_cleaned\\reviews_clean.csv and ..\\data_cleaned\\reviews_clean.parquet\n",
      "✅ reviews_clean.csv saved!\n",
      "Shape: (99224, 2)\n",
      "                           order_id  review_score\n",
      "0  73fc7af87114b39712e6da79b0a377eb             4\n",
      "1  a548910a1c6147796b98fdf73dbeba33             5\n",
      "2  f9e4b658b201a9f2ecdecbb34bed034b             5\n",
      "3  658677c97b385a9be170737859d3511b             5\n",
      "4  8e6bfb81e283fa7e4f11123a3fb894f1             5\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned translation table\n",
    "# Ensure the output directory exists and save the cleaned lookup table\n",
    "# ------------------------------------------------------------------------------\n",
    "export_clean(reviews_clean, \"reviews_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity checks\n",
    "# Quick validation of shape and sample rows\n",
    "# ------------------------------------------------------------------------------\n",
    "report(reviews_clean, \"reviews_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9576b62d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
