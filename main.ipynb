{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7da083b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\simon\\.cache\\kagglehub\\datasets\\olistbr\\brazilian-ecommerce\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "#Package to download datasets from kaggle\n",
    "#%pip install kagglehub\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6248d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_profile(df):\n",
    "    \"\"\"\n",
    "    Displays a quick profile of a pandas DataFrame.\n",
    "    Purpose: provide a high-level overview of the dataset structure,\n",
    "    data quality, and basic statistics (quick EDA).\n",
    "    \"\"\"\n",
    "\n",
    "    # Shape of the DataFrame: (number of rows, number of columns)\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "\n",
    "    # List of column names\n",
    "    print(f\"\\nData columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Data types of each column (int, float, object, datetime, etc.)\n",
    "    print(f\"\\nData types: {df.dtypes}\")\n",
    "\n",
    "    # Descriptive statistics for numerical variables\n",
    "    # Includes: count, mean, std, min, quartiles, and max\n",
    "    print(f\"\\nData description: {df.describe()}\")\n",
    "\n",
    "    # Number of missing values per column\n",
    "    # Helps identify data quality issues\n",
    "    print(f\"\\nData missing values: {df.isnull().sum()}\")\n",
    "\n",
    "    # Number of duplicated rows in the DataFrame\n",
    "    # Important to detect potential bias in analysis\n",
    "    print(f\"\\nData duplicates: {df.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bbd6f",
   "metadata": {},
   "source": [
    "### 1. Orders Table\n",
    "\n",
    "#### 1.1 Data Profiling & Understanding\n",
    "\n",
    "- Reviewed the dataset structure, including shape, columns, data types, and sample records\n",
    "- Assessed data quality by checking missing values and the distribution of order statuses\n",
    "- Identified and documented key columns relevant to business and analytical objectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the orders dataset\n",
    "orders = pd.read_csv(os.path.join(path, \"olist_orders_dataset.csv\"))\n",
    "# Quick data profile\n",
    "data_profile(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0945f",
   "metadata": {},
   "source": [
    "#### 1.2 Orders Data Cleaning\n",
    "\n",
    "- Selected only the columns required for order lifecycle and delivery analysis:\n",
    "  - `order_id`\n",
    "  - `customer_id`\n",
    "  - `order_status`\n",
    "  - `order_purchase_timestamp`\n",
    "  - `order_delivered_customer_date`\n",
    "  - `order_estimated_delivery_date`\n",
    "\n",
    "- Converted all timestamp fields to `datetime` format for time-based analysis\n",
    "\n",
    "- Standardized `order_status` values to lowercase to ensure consistency\n",
    "\n",
    "- Removed early-stage order statuses considered as noise:\n",
    "  - `created` (5 rows)\n",
    "  - `approved` (2 rows)\n",
    "\n",
    "- Kept missing `order_delivered_customer_date` values unchanged to handle them later during delivery performance analysis\n",
    "\n",
    "- Saved the cleaned dataset to:\n",
    "  - `data_cleaned/orders_clean.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 1. Column selection\n",
    "# Keep only the columns required for order lifecycle and delivery analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "orders = orders[[\n",
    "    \"order_id\",\n",
    "    \"customer_id\",\n",
    "    \"order_status\",\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "]]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Date parsing\n",
    "# Convert timestamp columns to pandas datetime for time-based analysis\n",
    "# Invalid or malformed dates are coerced to NaT\n",
    "# ------------------------------------------------------------------------------\n",
    "date_cols = [\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "]\n",
    "\n",
    "for col in date_cols:\n",
    "    orders[col] = pd.to_datetime(orders[col], errors=\"coerce\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Categorical normalization\n",
    "# Standardize order_status values to lowercase to avoid case-related issues\n",
    "# ------------------------------------------------------------------------------\n",
    "orders[\"order_status\"] = orders[\"order_status\"].str.lower()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. Business rule filtering\n",
    "# Remove orders that are still in early lifecycle stages\n",
    "# (not yet relevant for delivery or performance analysis)\n",
    "# ------------------------------------------------------------------------------\n",
    "orders = orders[~orders[\"order_status\"].isin([\"created\", \"approved\"])]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. Export cleaned dataset\n",
    "# Save the cleaned orders table for downstream analysis and dashboarding\n",
    "# ------------------------------------------------------------------------------\n",
    "os.makedirs(\"data_cleaned\", exist_ok=True)\n",
    "orders.to_csv(\"data_cleaned/orders_clean.csv\", index=False)\n",
    "\n",
    "print(\"✅ orders_clean.csv saved!\")\n",
    "print(\"Final shape:\", orders.shape)\n",
    "print(orders.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922094d",
   "metadata": {},
   "source": [
    "### 2. Customers Table\n",
    "\n",
    "#### 2.1 Data Profiling & Understanding\n",
    "\n",
    "- Explored the dataset structure, including shape, columns, data types, and sample records\n",
    "- Assessed data quality by checking for missing values\n",
    "- Identified key columns aligned with business and analytical objectives:\n",
    "  - `customer_id`: primary key used to join with the orders table\n",
    "  - `customer_state`: used for regional and geographic analysis\n",
    "- Documented non-essential columns not required for the current analysis scope:\n",
    "  - `customer_unique_id`\n",
    "  - `customer_zip_code_prefix`\n",
    "  - `customer_city`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ee23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the customers dataset\n",
    "customers = pd.read_csv(os.path.join(path, \"olist_customers_dataset.csv\"))\n",
    "# Quick data profile\n",
    "data_profile(customers) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861d93c",
   "metadata": {},
   "source": [
    "#### 2.2 Customers Data Cleaning\n",
    "\n",
    "- Retained only the columns required for the analysis:\n",
    "  - `customer_id`\n",
    "  - `customer_state`\n",
    "- Removed non-essential columns not aligned with current business objectives:\n",
    "  - `customer_unique_id`\n",
    "  - `customer_zip_code_prefix`\n",
    "  - `customer_city`\n",
    "- Verified that no missing values remain in the cleaned dataset\n",
    "- Saved the cleaned dataset to:\n",
    "  - `data_cleaned/customers_clean.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b9cbfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ customers_clean.csv saved!\n",
      "Final shape: (99441, 2)\n",
      "                        customer_id customer_state\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7             SP\n",
      "1  18955e83d337fd6b2def6b18a428ac77             SP\n",
      "2  4e7b3e00288586ebd08712fdd0374a03             SP\n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3             SP\n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad             SP\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 1. Column selection\n",
    "# Keep only the columns required for customer-level and regional analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "customers = customers[[\n",
    "    \"customer_id\",\n",
    "    \"customer_state\"\n",
    "]]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Export cleaned dataset\n",
    "# Ensure the output directory exists and save the cleaned table\n",
    "# ------------------------------------------------------------------------------\n",
    "os.makedirs(\"data_cleaned\", exist_ok=True)\n",
    "customers.to_csv(\"data_cleaned/customers_clean.csv\", index=False)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Sanity checks\n",
    "# Display basic information to validate the cleaning process\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"✅ customers_clean.csv saved!\")\n",
    "print(\"Final shape:\", customers.shape)\n",
    "print(customers.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
