{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Package to download datasets from kaggle\n",
    "#%pip install kagglehub\n",
    "# %pip install fastparquet\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_profile(df):\n",
    "    \"\"\"\n",
    "    Displays a quick profile of a pandas DataFrame.\n",
    "    Purpose: provide a high-level overview of the dataset structure,\n",
    "    data quality, and basic statistics (quick EDA).\n",
    "    \"\"\"\n",
    "\n",
    "    # Shape of the DataFrame: (number of rows, number of columns)\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "\n",
    "    # List of column names\n",
    "    print(f\"\\nData columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Data types of each column (int, float, object, datetime, etc.)\n",
    "    print(f\"\\nData types: {df.dtypes}\")\n",
    "\n",
    "    # Descriptive statistics for numerical variables\n",
    "    # Includes: count, mean, std, min, quartiles, and max\n",
    "    print(f\"\\nData description: {df.describe()}\")\n",
    "\n",
    "    # Number of missing values per column\n",
    "    # Helps identify data quality issues\n",
    "    print(f\"\\nData missing values: {df.isnull().sum()}\")\n",
    "\n",
    "    # Number of duplicated rows in the DataFrame\n",
    "    # Important to detect potential bias in analysis\n",
    "    print(f\"\\nData duplicates: {df.duplicated().sum()}\")\n",
    "\n",
    "\n",
    "def report(df, name):\n",
    "    \"\"\"\n",
    "    Display a quick validation report for a DataFrame.\n",
    "\n",
    "    Purpose:\n",
    "    - Confirm that the dataset has been correctly processed\n",
    "    - Provide a lightweight sanity check after cleaning or transformation steps\n",
    "    \"\"\"\n",
    "\n",
    "    # Display dataset name for traceability in the pipeline\n",
    "    print(f\"✅ {name}.csv saved!\")\n",
    "\n",
    "    # Print the DataFrame shape (rows, columns) to validate size expectations\n",
    "    print(\"Shape:\", df.shape)\n",
    "\n",
    "    # Display the first rows to visually inspect the output\n",
    "    print(df.head())\n",
    "\n",
    "\n",
    "def export_clean(df, name, out_dir=\"data_cleaned\"):\n",
    "    \"\"\"\n",
    "    Export a cleaned DataFrame to both CSV and Parquet formats.\n",
    "\n",
    "    Purpose:\n",
    "    - CSV: human-readable format for inspection and versioning\n",
    "    - Parquet: optimized columnar format for performance and type safety\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Build output file paths\n",
    "    csv_path = os.path.join(out_dir, f\"{name}.csv\")\n",
    "    parquet_path = os.path.join(out_dir, f\"{name}.parquet\")\n",
    "\n",
    "    # Export to CSV (universal, easy to inspect)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Export to Parquet using pyarrow\n",
    "    # This approach bypasses some pandas/pyarrow compatibility issues\n",
    "    # and ensures a robust Parquet write\n",
    "    table = pa.Table.from_pandas(df, preserve_index=False)\n",
    "    pq.write_table(table, parquet_path)\n",
    "\n",
    "    # Confirmation message\n",
    "    print(f\"✅ Saved: {csv_path} and {parquet_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bbd6f",
   "metadata": {},
   "source": [
    "### 1. Orders Table\n",
    "\n",
    "#### 1.1 Load raw data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the orders dataset\n",
    "orders_raw = pd.read_csv(os.path.join(path, \"olist_orders_dataset.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e35a77f",
   "metadata": {},
   "source": [
    "#### 1.2 Profiling\n",
    "\n",
    "- Reviewed dataset structure, columns, and data types\n",
    "- Analyzed order status distribution\n",
    "- Identified key timestamps for order lifecycle analysis\n",
    "- Flagged early-stage statuses not relevant for delivery performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data profile\n",
    "data_profile(orders_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0945f",
   "metadata": {},
   "source": [
    "#### 1.3 Data Cleaning\n",
    "\n",
    "- Selected columns required for order lifecycle and delivery analysis\n",
    "- Converted timestamp fields to datetime format\n",
    "- Standardized order_status values to lowercase\n",
    "- Excluded early-stage orders (`created`, `approved`)\n",
    "- Applied data quality checks (primary key uniqueness, non-null status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Column selection\n",
    "# Keep only the columns required for order lifecycle and delivery analysis\n",
    "# Use .copy() to avoid pandas chained assignment issues (SettingWithCopyWarning)\n",
    "# ------------------------------------------------------------------------------\n",
    "orders_clean = orders_raw[[\n",
    "    \"order_id\",\n",
    "    \"customer_id\",\n",
    "    \"order_status\",\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "]].copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Date parsing\n",
    "# Convert timestamp columns to pandas datetime for time-based analysis\n",
    "# Invalid or malformed values are coerced to NaT (missing)\n",
    "# ------------------------------------------------------------------------------\n",
    "date_cols = [\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "]\n",
    "orders_clean[date_cols] = orders_clean[date_cols].apply(pd.to_datetime, errors=\"coerce\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Categorical normalization\n",
    "# Standardize order_status values to lowercase to prevent case inconsistencies\n",
    "# ------------------------------------------------------------------------------\n",
    "orders_clean[\"order_status\"] = orders_clean[\"order_status\"].str.lower()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Business rule filtering\n",
    "# Exclude early-stage orders that are not relevant for delivery/performance analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "EXCLUDED_ORDER_STATUSES = {\"created\", \"approved\"}\n",
    "orders_clean = orders_clean.loc[\n",
    "    ~orders_clean[\"order_status\"].isin(EXCLUDED_ORDER_STATUSES)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d7141",
   "metadata": {},
   "source": [
    "#### 1.4 Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Stop the pipeline early if key assumptions are violated\n",
    "# ------------------------------------------------------------------------------\n",
    "assert orders_clean[\"order_id\"].notna().all(), \"order_id contains missing values\"\n",
    "assert orders_clean[\"order_id\"].is_unique, \"order_id is not unique\"\n",
    "assert orders_clean[\"order_status\"].notna().all(), \"order_status contains missing values\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4502388f",
   "metadata": {},
   "source": [
    "#### 1.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/orders_clean.csv`\n",
    "- `data_cleaned/orders_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned dataset\n",
    "# Save the cleaned table for downstream analysis and dashboarding\n",
    "# ------------------------------------------------------------------------------\n",
    "export_clean(orders_clean, \"orders_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity check report\n",
    "# Quick visual validation: shape + head\n",
    "# ------------------------------------------------------------------------------\n",
    "report(orders_clean, \"orders_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922094d",
   "metadata": {},
   "source": [
    "### 2. Customers Table\n",
    "\n",
    "#### 2.1 Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ee23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the customers dataset\n",
    "customers_raw = pd.read_csv(os.path.join(path, \"olist_customers_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2f9cf",
   "metadata": {},
   "source": [
    "#### 2.2 Profiling\n",
    "\n",
    "- Inspected dataset structure and data types\n",
    "- Checked for missing values\n",
    "- Identified customer_id as the primary key\n",
    "- Identified customer_state for regional analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a69a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data profile\n",
    "data_profile(customers_raw) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c342bf69",
   "metadata": {},
   "source": [
    "#### 2.3 Data cleaning\n",
    "\n",
    "- Retained only customer_id and customer_state\n",
    "- Applied data quality checks (primary key uniqueness, non-null state codes)\n",
    "- Validated customer_state format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9cbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Column selection\n",
    "# Keep only the columns required for customer-level and regional analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "customers_clean = customers_raw[[\n",
    "    \"customer_id\",\n",
    "    \"customer_state\"\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af833b77",
   "metadata": {},
   "source": [
    "#### 2.4 Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c86c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Validate key assumptions before exporting the dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Primary key checks\n",
    "assert customers_clean[\"customer_id\"].notna().all(), \\\n",
    "    \"customer_id contains missing values\"\n",
    "assert customers_clean[\"customer_id\"].is_unique, \\\n",
    "    \"customer_id is not unique\"\n",
    "\n",
    "# Categorical integrity checks\n",
    "assert customers_clean[\"customer_state\"].notna().all(), \\\n",
    "    \"customer_state contains missing values\"\n",
    "\n",
    "# Optional: validate state code format (Brazilian states = 2-letter codes)\n",
    "assert customers_clean[\"customer_state\"].str.len().eq(2).all(), \\\n",
    "    \"Invalid customer_state code detected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89766b15",
   "metadata": {},
   "source": [
    "#### 2.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/customers_clean.csv`\n",
    "- `data_cleaned/customers_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned dataset\n",
    "# Ensure the output directory exists and save the cleaned table\n",
    "# ------------------------------------------------------------------------------\n",
    "# os.makedirs(\"data_cleaned\", exist_ok=True)\n",
    "export_clean(customers_clean, \"customers_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity checks\n",
    "# Display basic information to validate the cleaning process\n",
    "# ------------------------------------------------------------------------------\n",
    "report(customers_clean, \"customers_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd875e6",
   "metadata": {},
   "source": [
    "### 3. Order Items Table\n",
    "\n",
    "#### 3.1 Load raw data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4080b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items_raw = pd.read_csv(os.path.join(path, \"olist_order_items_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb22011",
   "metadata": {},
   "source": [
    "#### 3.2 Profiling\n",
    "\n",
    "- Reviewed dataset structure and data types\n",
    "- Analyzed price and freight_value distributions\n",
    "- Identified key columns for revenue and shipping cost analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Order items – Data profiling\n",
    "# Explore structure, data quality, and key numerical metrics\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Generate a high-level overview of the raw order_items dataset\n",
    "# (shape, columns, data types, missing values, duplicates)\n",
    "data_profile(order_items_raw)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Numerical exploration: price\n",
    "# Analyze distribution and summary statistics to understand revenue patterns\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\nPrice summary:\")\n",
    "print(order_items_raw[\"price\"].describe())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Numerical exploration: freight_value\n",
    "# Analyze shipping cost distribution and identify potential outliers\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\nFreight summary:\")\n",
    "print(order_items_raw[\"freight_value\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b7f4c",
   "metadata": {},
   "source": [
    "#### 3.3 Data Cleaning\n",
    "\n",
    "- Selected relevant columns for analysis\n",
    "- Converted price and freight_value to numeric types\n",
    "- Applied data quality checks (non-null, non-negative values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08337c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Column selection\n",
    "# Keep only the columns required for revenue and shipping cost analysis\n",
    "# Use .copy() to avoid chained assignment issues\n",
    "# ------------------------------------------------------------------------------\n",
    "order_items_clean = order_items_raw[[\n",
    "    \"order_id\",\n",
    "    \"product_id\",\n",
    "    \"price\",\n",
    "    \"freight_value\"\n",
    "]].copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Data type conversion\n",
    "# Ensure price and freight_value are numeric for reliable aggregations\n",
    "# Invalid values are coerced to NaN\n",
    "# ------------------------------------------------------------------------------\n",
    "order_items_clean[\"price\"] = pd.to_numeric(\n",
    "    order_items_clean[\"price\"], errors=\"coerce\"\n",
    ")\n",
    "order_items_clean[\"freight_value\"] = pd.to_numeric(\n",
    "    order_items_clean[\"freight_value\"], errors=\"coerce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00706fa7",
   "metadata": {},
   "source": [
    "#### 3.4 Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Validate business assumptions before exporting the dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "assert order_items_clean[\"price\"].notna().all(), \"Missing values detected in price\"\n",
    "assert order_items_clean[\"freight_value\"].notna().all(), \"Missing values detected in freight_value\"\n",
    "\n",
    "assert (order_items_clean[\"price\"] >= 0).all(), \"Negative price values detected\"\n",
    "assert (order_items_clean[\"freight_value\"] >= 0).all(), \"Negative freight values detected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f00ace",
   "metadata": {},
   "source": [
    "#### 3.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/order_items_clean.csv`\n",
    "- `data_cleaned/order_items_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned dataset\n",
    "# Save the cleaned order items table for downstream analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "export_clean(order_items_clean, \"order_items_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity check report\n",
    "# Quick validation of shape and sample rows\n",
    "# ------------------------------------------------------------------------------\n",
    "report(order_items_clean, \"order_items_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba47a5",
   "metadata": {},
   "source": [
    "### 4. Products Table\n",
    "\n",
    "#### 4.1 Load raw data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34484c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Load products dataset\n",
    "# Read the raw products table from the source CSV file\n",
    "# ------------------------------------------------------------------------------\n",
    "products_raw = pd.read_csv(os.path.join(path, \"olist_products_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab51bc",
   "metadata": {},
   "source": [
    "#### 4.2 Profiling\n",
    "\n",
    "- Inspected dataset structure and category distribution\n",
    "- Identified product_category_name as the main analytical dimension\n",
    "- Flagged descriptive and physical attributes as out of scope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb759f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Initial data profiling\n",
    "# Generate a high-level overview of the dataset structure and data quality\n",
    "# ------------------------------------------------------------------------------\n",
    "data_profile(products_raw)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Categorical exploration\n",
    "# Analyze product categories to understand cardinality and sample values\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\nUnique categories:\", products_raw[\"product_category_name\"].nunique())\n",
    "\n",
    "# Display a sample of category values for quick inspection\n",
    "print(products_raw[\"product_category_name\"].unique()[:15])  # first 15 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feb4ce1",
   "metadata": {},
   "source": [
    "#### 4.3 Data Cleaning\n",
    "\n",
    "- Retained product_id and product_category_name\n",
    "- Replaced missing categories with \"unknown\"\n",
    "- Standardized category values\n",
    "- Applied data quality checks (primary key uniqueness, non-empty categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0502de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Column selection\n",
    "# Keep only the fields required for product-level and category analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "products_clean = products_raw[[\n",
    "    \"product_id\",\n",
    "    \"product_category_name\"\n",
    "]].copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Missing value handling\n",
    "# Replace missing product categories with \"unknown\" to preserve completeness\n",
    "# and avoid issues during grouping or joins\n",
    "# ------------------------------------------------------------------------------\n",
    "products_clean[\"product_category_name\"] = (\n",
    "    products_clean[\"product_category_name\"]\n",
    "    .fillna(\"unknown\")\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d31ee",
   "metadata": {},
   "source": [
    "#### 4.4 Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Validate key assumptions before exporting the dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Primary key checks\n",
    "assert products_clean[\"product_id\"].notna().all(), \"product_id contains missing values\"\n",
    "assert products_clean[\"product_id\"].is_unique, \"product_id is not unique\"\n",
    "\n",
    "# Category checks\n",
    "assert products_clean[\"product_category_name\"].notna().all(), \\\n",
    "    \"product_category_name contains missing values after fillna\"\n",
    "\n",
    "# No empty strings after cleaning\n",
    "assert (products_clean[\"product_category_name\"].str.len() > 0).all(), \\\n",
    "    \"Empty product_category_name values detected\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53bbf50",
   "metadata": {},
   "source": [
    "#### 4.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/products_clean.csv`\n",
    "- `data_cleaned/products_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned dataset\n",
    "# Save the cleaned products table for downstream analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "export_clean(products_clean, \"products_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity checks\n",
    "# Quick validation of shape and sample rows\n",
    "# ------------------------------------------------------------------------------\n",
    "report(products_clean, \"products_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec47fc",
   "metadata": {},
   "source": [
    "### 5. Product Category Translation Table\n",
    "\n",
    "#### 5.1 Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Load category translation table\n",
    "# Read the product category translation lookup table\n",
    "# (Portuguese → English)\n",
    "# ------------------------------------------------------------------------------\n",
    "translation_table_raw = pd.read_csv(\n",
    "    os.path.join(path, \"product_category_name_translation.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff1bb4c",
   "metadata": {},
   "source": [
    "#### 5.2 Profiling\n",
    "\n",
    "- Reviewed lookup table structure\n",
    "- Confirmed absence of missing values\n",
    "- Identified the table as a Portuguese-to-English category mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6149644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Initial data profiling\n",
    "# Generate a high-level overview to validate structure and data quality\n",
    "# ------------------------------------------------------------------------------\n",
    "data_profile(translation_table_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666163a",
   "metadata": {},
   "source": [
    "#### 5.3 Data Cleaning\n",
    "\n",
    "- Renamed columns for clarity\n",
    "- Standardized text fields\n",
    "- Applied data quality checks (unique mapping, non-null values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd381d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Column renaming\n",
    "# Rename columns to improve clarity and semantic meaning\n",
    "# ------------------------------------------------------------------------------\n",
    "translation_table_clean = translation_table_raw.rename(columns={\n",
    "    \"product_category_name\": \"category_portuguese\",\n",
    "    \"product_category_name_english\": \"category_english\"\n",
    "}).copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# String normalization\n",
    "# Standardize text fields to reduce join mismatches (spaces/case)\n",
    "# ------------------------------------------------------------------------------\n",
    "translation_table_clean[\"category_portuguese\"] = (\n",
    "    translation_table_clean[\"category_portuguese\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "translation_table_clean[\"category_english\"] = (\n",
    "    translation_table_clean[\"category_english\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8362e3a6",
   "metadata": {},
   "source": [
    "#### 5.4  Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f387e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Validate lookup integrity before exporting the dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# No missing values (expected for a translation lookup table)\n",
    "assert translation_table_clean[\"category_portuguese\"].notna().all(), \\\n",
    "    \"category_portuguese contains missing values\"\n",
    "assert translation_table_clean[\"category_english\"].notna().all(), \\\n",
    "    \"category_english contains missing values\"\n",
    "\n",
    "# No empty strings after cleaning\n",
    "assert (translation_table_clean[\"category_portuguese\"].str.len() > 0).all(), \\\n",
    "    \"Empty category_portuguese values detected\"\n",
    "assert (translation_table_clean[\"category_english\"].str.len() > 0).all(), \\\n",
    "    \"Empty category_english values detected\"\n",
    "\n",
    "# Key uniqueness: one Portuguese category should map to one English category\n",
    "assert translation_table_clean[\"category_portuguese\"].is_unique, \\\n",
    "    \"Duplicate category_portuguese detected (mapping should be 1-to-1)\"\n",
    "\n",
    "# Optional: sanity check for duplicates on the full pair (PT, EN)\n",
    "assert translation_table_clean.duplicated(\n",
    "    subset=[\"category_portuguese\", \"category_english\"]\n",
    ").sum() == 0, \"Duplicate translation pairs detected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d444af",
   "metadata": {},
   "source": [
    "#### 5.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/category_translation_clean.csv`\n",
    "- `data_cleaned/category_translation_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned translation table\n",
    "# Ensure the output directory exists and save the cleaned lookup table\n",
    "# ------------------------------------------------------------------------------\n",
    "export_clean(translation_table_clean, \"translation_table_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity checks\n",
    "# Quick validation of shape and sample rows\n",
    "# ------------------------------------------------------------------------------\n",
    "report(translation_table_clean, \"translation_table_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86cc5c9",
   "metadata": {},
   "source": [
    "### 6. Reviews Table\n",
    "\n",
    "#### 6.1 Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea270074",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_table_raw = pd.read_csv(\n",
    "    os.path.join(path, \"olist_order_reviews_dataset.csv\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf1abe",
   "metadata": {},
   "source": [
    "#### 6.2 Profiling\n",
    "\n",
    "- Reviewed dataset structure, columns, and data types\n",
    "- Identified `order_id` as the join key with the orders table\n",
    "- Analyzed the distribution of `review_score` to assess customer satisfaction patterns\n",
    "- Verified that review scores follow a discrete rating scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_profile(reviews_table_raw)\n",
    "\n",
    "print(\"\\nReview score distribution:\")\n",
    "print(reviews_table_raw['review_score'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d22e3",
   "metadata": {},
   "source": [
    "#### 6.3 Data Cleaning\n",
    "\n",
    "- Selected only the columns required for satisfaction analysis:\n",
    "  - `order_id`\n",
    "  - `review_score`\n",
    "- Ensured `review_score` values are numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_table_clean = reviews_table_raw[[\"order_id\", \"review_score\"]].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3488144f",
   "metadata": {},
   "source": [
    "#### 6.4 Data quality checks\n",
    "\n",
    "- Applied data quality checks:\n",
    "  - non-null `order_id`\n",
    "  - non-null `review_score`\n",
    "  - review scores constrained to the expected range (1–5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aaaa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Data quality checks (assertions)\n",
    "# Validate assumptions for reviews data\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# order_id must be present for joins with orders\n",
    "assert reviews_table_clean[\"order_id\"].notna().all(), \\\n",
    "    \"order_id contains missing values in reviews table\"\n",
    "\n",
    "# review_score must be present\n",
    "assert reviews_table_clean[\"review_score\"].notna().all(), \\\n",
    "    \"review_score contains missing values\"\n",
    "\n",
    "# review_score must be numeric\n",
    "assert pd.api.types.is_numeric_dtype(reviews_table_clean[\"review_score\"]), \\\n",
    "    \"review_score is not numeric\"\n",
    "\n",
    "# review_score must be within expected rating scale (1 to 5)\n",
    "assert reviews_table_clean[\"review_score\"].between(1, 5).all(), \\\n",
    "    \"review_score outside expected range (1–5)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde901cd",
   "metadata": {},
   "source": [
    "#### 5.5 Export\n",
    "\n",
    "**Output**\n",
    "- `data_cleaned/reviews_table_clean.csv`\n",
    "- `data_cleaned/reviews_table_clean.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43351fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Export cleaned translation table\n",
    "# Ensure the output directory exists and save the cleaned lookup table\n",
    "# ------------------------------------------------------------------------------\n",
    "export_clean(reviews_table_clean, \"reviews_table_clean\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Sanity checks\n",
    "# Quick validation of shape and sample rows\n",
    "# ------------------------------------------------------------------------------\n",
    "report(reviews_table_clean, \"reviews_table_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9576b62d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
