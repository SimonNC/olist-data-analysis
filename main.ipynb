{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7da083b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\simon\\.cache\\kagglehub\\datasets\\olistbr\\brazilian-ecommerce\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "#Package to download datasets from kaggle\n",
    "#%pip install kagglehub\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6248d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_profile(df):\n",
    "    \"\"\"\n",
    "    Displays a quick profile of a pandas DataFrame.\n",
    "    Purpose: provide a high-level overview of the dataset structure,\n",
    "    data quality, and basic statistics (quick EDA).\n",
    "    \"\"\"\n",
    "\n",
    "    # Shape of the DataFrame: (number of rows, number of columns)\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "\n",
    "    # List of column names\n",
    "    print(f\"\\nData columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Data types of each column (int, float, object, datetime, etc.)\n",
    "    print(f\"\\nData types: {df.dtypes}\")\n",
    "\n",
    "    # Descriptive statistics for numerical variables\n",
    "    # Includes: count, mean, std, min, quartiles, and max\n",
    "    print(f\"\\nData description: {df.describe()}\")\n",
    "\n",
    "    # Number of missing values per column\n",
    "    # Helps identify data quality issues\n",
    "    print(f\"\\nData missing values: {df.isnull().sum()}\")\n",
    "\n",
    "    # Number of duplicated rows in the DataFrame\n",
    "    # Important to detect potential bias in analysis\n",
    "    print(f\"\\nData duplicates: {df.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bbd6f",
   "metadata": {},
   "source": [
    "### 1. Orders Table\n",
    "\n",
    "#### 1.1 Data Profiling & Understanding\n",
    "\n",
    "- Reviewed the dataset structure, including shape, columns, data types, and sample records\n",
    "- Assessed data quality by checking missing values and the distribution of order statuses\n",
    "- Identified and documented key columns relevant to business and analytical objectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the orders dataset\n",
    "orders = pd.read_csv(os.path.join(path, \"olist_orders_dataset.csv\"))\n",
    "# Quick data profile\n",
    "data_profile(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0945f",
   "metadata": {},
   "source": [
    "#### 1.2 Orders Data Cleaning\n",
    "\n",
    "- Selected only the columns required for order lifecycle and delivery analysis:\n",
    "  - `order_id`\n",
    "  - `customer_id`\n",
    "  - `order_status`\n",
    "  - `order_purchase_timestamp`\n",
    "  - `order_delivered_customer_date`\n",
    "  - `order_estimated_delivery_date`\n",
    "\n",
    "- Converted all timestamp fields to `datetime` format for time-based analysis\n",
    "\n",
    "- Standardized `order_status` values to lowercase to ensure consistency\n",
    "\n",
    "- Removed early-stage order statuses considered as noise:\n",
    "  - `created` (5 rows)\n",
    "  - `approved` (2 rows)\n",
    "\n",
    "- Kept missing `order_delivered_customer_date` values unchanged to handle them later during delivery performance analysis\n",
    "\n",
    "- Saved the cleaned dataset to:\n",
    "  - `data_cleaned/orders_clean.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 1. Column selection\n",
    "# Keep only the columns required for order lifecycle and delivery analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "orders = orders[[\n",
    "    \"order_id\",\n",
    "    \"customer_id\",\n",
    "    \"order_status\",\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "]]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Date parsing\n",
    "# Convert timestamp columns to pandas datetime for time-based analysis\n",
    "# Invalid or malformed dates are coerced to NaT\n",
    "# ------------------------------------------------------------------------------\n",
    "date_cols = [\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "]\n",
    "\n",
    "for col in date_cols:\n",
    "    orders[col] = pd.to_datetime(orders[col], errors=\"coerce\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Categorical normalization\n",
    "# Standardize order_status values to lowercase to avoid case-related issues\n",
    "# ------------------------------------------------------------------------------\n",
    "orders[\"order_status\"] = orders[\"order_status\"].str.lower()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. Business rule filtering\n",
    "# Remove orders that are still in early lifecycle stages\n",
    "# (not yet relevant for delivery or performance analysis)\n",
    "# ------------------------------------------------------------------------------\n",
    "orders = orders[~orders[\"order_status\"].isin([\"created\", \"approved\"])]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. Export cleaned dataset\n",
    "# Save the cleaned orders table for downstream analysis and dashboarding\n",
    "# ------------------------------------------------------------------------------\n",
    "os.makedirs(\"data_cleaned\", exist_ok=True)\n",
    "orders.to_csv(\"data_cleaned/orders_clean.csv\", index=False)\n",
    "\n",
    "print(\"✅ orders_clean.csv saved!\")\n",
    "print(\"Final shape:\", orders.shape)\n",
    "print(orders.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922094d",
   "metadata": {},
   "source": [
    "### 2. Customers Table\n",
    "\n",
    "#### 2.1 Data Profiling & Understanding\n",
    "\n",
    "- Explored the dataset structure, including shape, columns, data types, and sample records\n",
    "- Assessed data quality by checking for missing values\n",
    "- Identified key columns aligned with business and analytical objectives:\n",
    "  - `customer_id`: primary key used to join with the orders table\n",
    "  - `customer_state`: used for regional and geographic analysis\n",
    "- Documented non-essential columns not required for the current analysis scope:\n",
    "  - `customer_unique_id`\n",
    "  - `customer_zip_code_prefix`\n",
    "  - `customer_city`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ee23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the customers dataset\n",
    "customers = pd.read_csv(os.path.join(path, \"olist_customers_dataset.csv\"))\n",
    "# Quick data profile\n",
    "data_profile(customers) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861d93c",
   "metadata": {},
   "source": [
    "#### 2.2 Customers Data Cleaning\n",
    "\n",
    "- Retained only the columns required for the analysis:\n",
    "  - `customer_id`\n",
    "  - `customer_state`\n",
    "- Removed non-essential columns not aligned with current business objectives:\n",
    "  - `customer_unique_id`\n",
    "  - `customer_zip_code_prefix`\n",
    "  - `customer_city`\n",
    "- Verified that no missing values remain in the cleaned dataset\n",
    "- Saved the cleaned dataset to:\n",
    "  - `data_cleaned/customers_clean.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9cbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 1. Column selection\n",
    "# Keep only the columns required for customer-level and regional analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "customers = customers[[\n",
    "    \"customer_id\",\n",
    "    \"customer_state\"\n",
    "]]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Export cleaned dataset\n",
    "# Ensure the output directory exists and save the cleaned table\n",
    "# ------------------------------------------------------------------------------\n",
    "os.makedirs(\"data_cleaned\", exist_ok=True)\n",
    "customers.to_csv(\"data_cleaned/customers_clean.csv\", index=False)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Sanity checks\n",
    "# Display basic information to validate the cleaning process\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"✅ customers_clean.csv saved!\")\n",
    "print(\"Final shape:\", customers.shape)\n",
    "print(customers.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd875e6",
   "metadata": {},
   "source": [
    "### 3. Order Items Table\n",
    "\n",
    "#### 3.1 Data Profiling & Understanding\n",
    "\n",
    "- Explored the dataset structure, including shape, columns, data types, and sample records\n",
    "- Checked for missing values to assess data quality\n",
    "- Reviewed the distributions of `price` and `freight_value` to understand revenue and shipping cost patterns\n",
    "- Identified key columns aligned with business and analytical objectives:\n",
    "  - `order_id`: used to join with the orders table\n",
    "  - `product_id`: used to join with the products table\n",
    "  - `price`: used for revenue calculations\n",
    "  - `freight_value`: used for shipping cost analysis\n",
    "- Documented columns not required for the current analysis scope:\n",
    "  - `order_item_id`\n",
    "  - `seller_id`\n",
    "  - `shipping_limit_date`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items = pd.read_csv(os.path.join(path, \"olist_order_items_dataset.csv\"))\n",
    "data_profile(order_items)\n",
    "print(\"\\nPrice summary:\")\n",
    "print(order_items['price'].describe())\n",
    "\n",
    "print(\"\\nFreight summary:\")\n",
    "print(order_items['freight_value'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b7f4c",
   "metadata": {},
   "source": [
    "#### 3.2 Order Items Data Cleaning\n",
    "\n",
    "- Retained only the columns required for revenue and shipping cost analysis:\n",
    "  - `order_id`\n",
    "  - `product_id`\n",
    "  - `price`\n",
    "  - `freight_value`\n",
    "- Removed non-essential columns not aligned with current analytical objectives:\n",
    "  - `order_item_id`\n",
    "  - `seller_id`\n",
    "  - `shipping_limit_date`\n",
    "- Verified that `price` and `freight_value` are stored as numeric values\n",
    "- Saved the cleaned dataset to:\n",
    "  - `data_cleaned/order_items_clean.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08337c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns we need for analysis\n",
    "order_items = order_items[[\"order_id\", \"product_id\", \"price\", \"freight_value\"]]\n",
    "order_items[\"price\"] = pd.to_numeric(order_items[\"price\"], errors=\"coerce\")\n",
    "order_items[\"freight_value\"] = pd.to_numeric(order_items[\"freight_value\"], errors=\"coerce\")\n",
    "\n",
    "# Save cleaned order items to a CSV file\n",
    "os.makedirs(\"data_cleaned\", exist_ok=True)\n",
    "order_items.to_csv(\"data_cleaned/order_items_clean.csv\", index=False)\n",
    "\n",
    "print(\"✅ order_items_clean.csv saved! Shape:\", order_items.shape)\n",
    "print(order_items.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
