{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7da083b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\simon\\.cache\\kagglehub\\datasets\\olistbr\\brazilian-ecommerce\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "#Package to download datasets from kaggle\n",
    "#%pip install kagglehub\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6248d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_profile(df):\n",
    "    \"\"\"\n",
    "    Displays a quick profile of a pandas DataFrame.\n",
    "    Purpose: provide a high-level overview of the dataset structure,\n",
    "    data quality, and basic statistics (quick EDA).\n",
    "    \"\"\"\n",
    "\n",
    "    # Shape of the DataFrame: (number of rows, number of columns)\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "\n",
    "    # List of column names\n",
    "    print(f\"\\nData columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Data types of each column (int, float, object, datetime, etc.)\n",
    "    print(f\"\\nData types: {df.dtypes}\")\n",
    "\n",
    "    # Descriptive statistics for numerical variables\n",
    "    # Includes: count, mean, std, min, quartiles, and max\n",
    "    print(f\"\\nData description: {df.describe()}\")\n",
    "\n",
    "    # Number of missing values per column\n",
    "    # Helps identify data quality issues\n",
    "    print(f\"\\nData missing values: {df.isnull().sum()}\")\n",
    "\n",
    "    # Number of duplicated rows in the DataFrame\n",
    "    # Important to detect potential bias in analysis\n",
    "    print(f\"\\nData duplicates: {df.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bbd6f",
   "metadata": {},
   "source": [
    "1. Orders Table\n",
    "1.1 Data Profiling & Understanding\n",
    "\n",
    "-Reviewed dataset structure: shape, columns, data types, and sample records\n",
    "-Assessed data quality by checking missing values and the distribution of order statuses\n",
    "-Identified and documented key columns relevant to business and analytical objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the orders dataset\n",
    "orders = pd.read_csv(os.path.join(path, \"olist_orders_dataset.csv\"))\n",
    "# Quick data profile\n",
    "data_profile(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0945f",
   "metadata": {},
   "source": [
    "1.2 Orders Data Cleaning\n",
    "\n",
    "Selected only the columns required for order lifecycle and delivery analysis:\n",
    "order_id, customer_id, order_status, order_purchase_timestamp,order_delivered_customer_date, order_estimated_delivery_date\n",
    "\n",
    "Converted all timestamp fields to datetime format for time-based analysis\n",
    "\n",
    "Standardized order_status values to lowercase to ensure consistency\n",
    "\n",
    "Removed early-stage order statuses considered as noise:\n",
    "created (5 rows) and approved (2 rows)\n",
    "\n",
    "Kept missing order_delivered_customer_date values unchanged to handle them later during delivery performance analysis\n",
    "\n",
    "Saved the cleaned dataset to:\n",
    "data_cleaned/orders_clean.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 1. Column selection\n",
    "# Keep only the columns required for order lifecycle and delivery analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "orders = orders[[\n",
    "    \"order_id\",\n",
    "    \"customer_id\",\n",
    "    \"order_status\",\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "]]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Date parsing\n",
    "# Convert timestamp columns to pandas datetime for time-based analysis\n",
    "# Invalid or malformed dates are coerced to NaT\n",
    "# ------------------------------------------------------------------------------\n",
    "date_cols = [\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "]\n",
    "\n",
    "for col in date_cols:\n",
    "    orders[col] = pd.to_datetime(orders[col], errors=\"coerce\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Categorical normalization\n",
    "# Standardize order_status values to lowercase to avoid case-related issues\n",
    "# ------------------------------------------------------------------------------\n",
    "orders[\"order_status\"] = orders[\"order_status\"].str.lower()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. Business rule filtering\n",
    "# Remove orders that are still in early lifecycle stages\n",
    "# (not yet relevant for delivery or performance analysis)\n",
    "# ------------------------------------------------------------------------------\n",
    "orders = orders[~orders[\"order_status\"].isin([\"created\", \"approved\"])]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. Export cleaned dataset\n",
    "# Save the cleaned orders table for downstream analysis and dashboarding\n",
    "# ------------------------------------------------------------------------------\n",
    "os.makedirs(\"data_cleaned\", exist_ok=True)\n",
    "orders.to_csv(\"data_cleaned/orders_clean.csv\", index=False)\n",
    "\n",
    "print(\"âœ… orders_clean.csv saved!\")\n",
    "print(\"Final shape:\", orders.shape)\n",
    "print(orders.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
